{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f87b2d",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "Consider yourself to be Matt, who is a Deep Learning Engineer at a prestigious company. Your company \n",
    "is working with the National Institute of Diabetes to find out what are the factors which lead up to a \n",
    "patient having diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2e271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b74569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\GOPI CHAND\\Downloads\\diabetes\\diabetes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72c4987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1be1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "678757dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d992065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cb2b44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c94b0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.isna of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.isna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adc47a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.isnull of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e95e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfe073fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49968625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd5c0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5873b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:,['Pregnancies', 'Glucose', 'BloodPressure']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6916a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6, 148,  72],\n",
       "       [  1,  85,  66],\n",
       "       [  8, 183,  64],\n",
       "       ...,\n",
       "       [  5, 121,  72],\n",
       "       [  1, 126,  60],\n",
       "       [  1,  93,  70]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab1e0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6440e5",
   "metadata": {},
   "source": [
    "# A. Build a sequential model using Keras on top of this Diabetes dataset to find out if the \n",
    "patient has diabetes or not, using â€˜Pregnanciesâ€™, â€˜Glucoseâ€™ & â€˜BloodPressureâ€™ as \n",
    "independent columns. \n",
    "a. This model should have 1 hidden layer with 8 nodes \n",
    "b. Use Stochastic Gradient as the optimization algorithm \n",
    "c. Fit the model, with number of epochs to be 100 and batch size to be 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "206e8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Pregnancies', 'Glucose', 'BloodPressure']]\n",
    "target = df['Outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a6c8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47558930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fc81d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66c8552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8, activation='relu', input_shape=(3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d799e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bed3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e2eb7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 8)                 32        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41 (164.00 Byte)\n",
      "Trainable params: 41 (164.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "395e39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 8ms/step - loss: 0.7868 - accuracy: 0.4821 - val_loss: 0.7090 - val_accuracy: 0.5195\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7042 - accuracy: 0.5749 - val_loss: 0.6445 - val_accuracy: 0.6558\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.6503 - accuracy: 0.6547 - val_loss: 0.6001 - val_accuracy: 0.7143\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6857 - val_loss: 0.5699 - val_accuracy: 0.7273\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7117 - val_loss: 0.5491 - val_accuracy: 0.7403\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7101 - val_loss: 0.5349 - val_accuracy: 0.7662\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7134 - val_loss: 0.5256 - val_accuracy: 0.7597\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7182 - val_loss: 0.5185 - val_accuracy: 0.7727\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7248 - val_loss: 0.5135 - val_accuracy: 0.7727\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7329 - val_loss: 0.5098 - val_accuracy: 0.7727\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7280 - val_loss: 0.5063 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7296 - val_loss: 0.5034 - val_accuracy: 0.7792\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7345 - val_loss: 0.5010 - val_accuracy: 0.7792\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7345 - val_loss: 0.4991 - val_accuracy: 0.7792\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7378 - val_loss: 0.4977 - val_accuracy: 0.7792\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7459 - val_loss: 0.4964 - val_accuracy: 0.7792\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7476 - val_loss: 0.4954 - val_accuracy: 0.7792\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7492 - val_loss: 0.4943 - val_accuracy: 0.7727\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7492 - val_loss: 0.4942 - val_accuracy: 0.7792\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7508 - val_loss: 0.4940 - val_accuracy: 0.7727\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7492 - val_loss: 0.4933 - val_accuracy: 0.7727\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7508 - val_loss: 0.4933 - val_accuracy: 0.7727\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7508 - val_loss: 0.4929 - val_accuracy: 0.7727\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7492 - val_loss: 0.4925 - val_accuracy: 0.7727\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7492 - val_loss: 0.4927 - val_accuracy: 0.7792\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7492 - val_loss: 0.4927 - val_accuracy: 0.7792\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7508 - val_loss: 0.4929 - val_accuracy: 0.7792\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7492 - val_loss: 0.4923 - val_accuracy: 0.7792\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7508 - val_loss: 0.4921 - val_accuracy: 0.7792\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7492 - val_loss: 0.4921 - val_accuracy: 0.7792\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7524 - val_loss: 0.4922 - val_accuracy: 0.7792\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7492 - val_loss: 0.4917 - val_accuracy: 0.7792\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7524 - val_loss: 0.4918 - val_accuracy: 0.7792\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7508 - val_loss: 0.4911 - val_accuracy: 0.7792\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7508 - val_loss: 0.4911 - val_accuracy: 0.7727\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7524 - val_loss: 0.4910 - val_accuracy: 0.7792\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7492 - val_loss: 0.4906 - val_accuracy: 0.7857\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7508 - val_loss: 0.4910 - val_accuracy: 0.7727\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7476 - val_loss: 0.4905 - val_accuracy: 0.7727\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7524 - val_loss: 0.4901 - val_accuracy: 0.7727\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7476 - val_loss: 0.4904 - val_accuracy: 0.7727\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7508 - val_loss: 0.4895 - val_accuracy: 0.7792\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7524 - val_loss: 0.4893 - val_accuracy: 0.7792\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7476 - val_loss: 0.4899 - val_accuracy: 0.7792\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7541 - val_loss: 0.4890 - val_accuracy: 0.7792\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7492 - val_loss: 0.4894 - val_accuracy: 0.7727\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7541 - val_loss: 0.4890 - val_accuracy: 0.7792\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7508 - val_loss: 0.4887 - val_accuracy: 0.7727\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7508 - val_loss: 0.4883 - val_accuracy: 0.7792\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7508 - val_loss: 0.4886 - val_accuracy: 0.7792\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7508 - val_loss: 0.4878 - val_accuracy: 0.7857\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7524 - val_loss: 0.4881 - val_accuracy: 0.7792\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.4877 - val_accuracy: 0.7792\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.4868 - val_accuracy: 0.7792\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7508 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7508 - val_loss: 0.4871 - val_accuracy: 0.7792\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7524 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7524 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7508 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7524 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7524 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7541 - val_loss: 0.4864 - val_accuracy: 0.7922\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7541 - val_loss: 0.4865 - val_accuracy: 0.7922\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7524 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7524 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7508 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7541 - val_loss: 0.4857 - val_accuracy: 0.7857\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7524 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7508 - val_loss: 0.4858 - val_accuracy: 0.7857\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7524 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7492 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7508 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7476 - val_loss: 0.4861 - val_accuracy: 0.7857\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7492 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7508 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7508 - val_loss: 0.4865 - val_accuracy: 0.7922\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7508 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7492 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7492 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7508 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7476 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7508 - val_loss: 0.4867 - val_accuracy: 0.7857\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7492 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7492 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7492 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7476 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7508 - val_loss: 0.4857 - val_accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bda8ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bce84bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34c553",
   "metadata": {},
   "source": [
    "# B. Build another sequential model where â€˜Outcomeâ€™ is the dependent variable and all \n",
    "other columns are predictors. \n",
    "a. This model should have 3 hidden layers with 16 nodes in each layer \n",
    "b. Use â€˜adamâ€™ as the optimization algorithm \n",
    "c. Fit the model, with number of epochs to be 150 and batch size to be 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56f20465",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['SkinThickness', 'Insulin', 'BMI','DiabetesPedigreeFunction', 'Age']]\n",
    "target = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "033d4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de214b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.5, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19de631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5e906ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(16, activation='relu', input_shape=(3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eebe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84282fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6ac5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 16)                64        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115 (460.00 Byte)\n",
      "Trainable params: 115 (460.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21e9bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7443 - val_loss: 0.4861 - val_accuracy: 0.7857\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7476 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7508 - val_loss: 0.4855 - val_accuracy: 0.7857\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7476 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7508 - val_loss: 0.4853 - val_accuracy: 0.7857\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7476 - val_loss: 0.4858 - val_accuracy: 0.7857\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7492 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7508 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7476 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7492 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7508 - val_loss: 0.4857 - val_accuracy: 0.7857\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7476 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7492 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7476 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7459 - val_loss: 0.4858 - val_accuracy: 0.7857\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7476 - val_loss: 0.4858 - val_accuracy: 0.7857\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7476 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7476 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7476 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7476 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7476 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7492 - val_loss: 0.4864 - val_accuracy: 0.7922\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7492 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7492 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7459 - val_loss: 0.4867 - val_accuracy: 0.7857\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7476 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7492 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7476 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7492 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7508 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7524 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7508 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7508 - val_loss: 0.4865 - val_accuracy: 0.7857\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7492 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7508 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7492 - val_loss: 0.4863 - val_accuracy: 0.7857\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7508 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7508 - val_loss: 0.4861 - val_accuracy: 0.7857\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7508 - val_loss: 0.4858 - val_accuracy: 0.7857\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7492 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7492 - val_loss: 0.4861 - val_accuracy: 0.7857\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7857\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7492 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7492 - val_loss: 0.4867 - val_accuracy: 0.7857\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7492 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7492 - val_loss: 0.4867 - val_accuracy: 0.7857\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7459 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7508 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7508 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7476 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7492 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7492 - val_loss: 0.4872 - val_accuracy: 0.7857\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7508 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7476 - val_loss: 0.4874 - val_accuracy: 0.7857\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7508 - val_loss: 0.4867 - val_accuracy: 0.7857\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7476 - val_loss: 0.4870 - val_accuracy: 0.7922\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7508 - val_loss: 0.4869 - val_accuracy: 0.7857\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7492 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7476 - val_loss: 0.4870 - val_accuracy: 0.7857\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7476 - val_loss: 0.4872 - val_accuracy: 0.7857\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7508 - val_loss: 0.4869 - val_accuracy: 0.7857\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7476 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7492 - val_loss: 0.4869 - val_accuracy: 0.7857\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7508 - val_loss: 0.4870 - val_accuracy: 0.7857\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7492 - val_loss: 0.4870 - val_accuracy: 0.7857\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7492 - val_loss: 0.4871 - val_accuracy: 0.7857\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7492 - val_loss: 0.4870 - val_accuracy: 0.7857\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7476 - val_loss: 0.4880 - val_accuracy: 0.7857\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7492 - val_loss: 0.4875 - val_accuracy: 0.7857\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7492 - val_loss: 0.4872 - val_accuracy: 0.7857\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7476 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7492 - val_loss: 0.4874 - val_accuracy: 0.7857\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7476 - val_loss: 0.4869 - val_accuracy: 0.7857\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7492 - val_loss: 0.4870 - val_accuracy: 0.7857\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7492 - val_loss: 0.4875 - val_accuracy: 0.7987\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7492 - val_loss: 0.4875 - val_accuracy: 0.7857\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7492 - val_loss: 0.4877 - val_accuracy: 0.7857\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7476 - val_loss: 0.4878 - val_accuracy: 0.7987\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7492 - val_loss: 0.4877 - val_accuracy: 0.7857\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7508 - val_loss: 0.4878 - val_accuracy: 0.7857\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7508 - val_loss: 0.4877 - val_accuracy: 0.7922\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7492 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7492 - val_loss: 0.4881 - val_accuracy: 0.7987\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7492 - val_loss: 0.4879 - val_accuracy: 0.7857\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7476 - val_loss: 0.4876 - val_accuracy: 0.7857\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7476 - val_loss: 0.4878 - val_accuracy: 0.7987\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7524 - val_loss: 0.4879 - val_accuracy: 0.8052\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7508 - val_loss: 0.4878 - val_accuracy: 0.8052\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7476 - val_loss: 0.4883 - val_accuracy: 0.7987\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7508 - val_loss: 0.4875 - val_accuracy: 0.8052\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7492 - val_loss: 0.4875 - val_accuracy: 0.7987\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7508 - val_loss: 0.4872 - val_accuracy: 0.7922\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7492 - val_loss: 0.4871 - val_accuracy: 0.7922\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7492 - val_loss: 0.4874 - val_accuracy: 0.7987\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7492 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7508 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7508 - val_loss: 0.4870 - val_accuracy: 0.7987\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7541 - val_loss: 0.4864 - val_accuracy: 0.8052\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7492 - val_loss: 0.4865 - val_accuracy: 0.7922\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7508 - val_loss: 0.4873 - val_accuracy: 0.8052\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7508 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7492 - val_loss: 0.4867 - val_accuracy: 0.7987\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7524 - val_loss: 0.4868 - val_accuracy: 0.8052\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7508 - val_loss: 0.4864 - val_accuracy: 0.8052\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7508 - val_loss: 0.4867 - val_accuracy: 0.8052\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7492 - val_loss: 0.4869 - val_accuracy: 0.7987\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7524 - val_loss: 0.4865 - val_accuracy: 0.7987\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7508 - val_loss: 0.4867 - val_accuracy: 0.7987\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7492 - val_loss: 0.4870 - val_accuracy: 0.8052\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7541 - val_loss: 0.4866 - val_accuracy: 0.7857\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7492 - val_loss: 0.4869 - val_accuracy: 0.8052\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7524 - val_loss: 0.4871 - val_accuracy: 0.8052\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7476 - val_loss: 0.4870 - val_accuracy: 0.7987\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7541 - val_loss: 0.4866 - val_accuracy: 0.7987\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7476 - val_loss: 0.4860 - val_accuracy: 0.7987\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7508 - val_loss: 0.4862 - val_accuracy: 0.7987\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7492 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7541 - val_loss: 0.4867 - val_accuracy: 0.8052\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7541 - val_loss: 0.4865 - val_accuracy: 0.8052\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7524 - val_loss: 0.4866 - val_accuracy: 0.7922\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7857\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7476 - val_loss: 0.4869 - val_accuracy: 0.8052\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7476 - val_loss: 0.4860 - val_accuracy: 0.7857\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7492 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7922\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7459 - val_loss: 0.4867 - val_accuracy: 0.7987\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7541 - val_loss: 0.4863 - val_accuracy: 0.8052\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7476 - val_loss: 0.4861 - val_accuracy: 0.7922\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7508 - val_loss: 0.4865 - val_accuracy: 0.7987\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7508 - val_loss: 0.4863 - val_accuracy: 0.8052\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7476 - val_loss: 0.4855 - val_accuracy: 0.7987\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7476 - val_loss: 0.4861 - val_accuracy: 0.7857\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7492 - val_loss: 0.4859 - val_accuracy: 0.7922\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7476 - val_loss: 0.4855 - val_accuracy: 0.7922\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7492 - val_loss: 0.4858 - val_accuracy: 0.8052\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7508 - val_loss: 0.4857 - val_accuracy: 0.7987\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7492 - val_loss: 0.4859 - val_accuracy: 0.8052\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7508 - val_loss: 0.4854 - val_accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ee5eb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7922\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0d43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
